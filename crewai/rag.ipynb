{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Load and split docs\n",
    "loader = CSVLoader(file_path=r'D:\\Users\\ramadeepthi.galla\\Documents\\sample.csv')\n",
    "docs = loader.load()\n",
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79076d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings using Gemini\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783463f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorstore\n",
    "vectorstore = FAISS.from_documents(chunks, embedding)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Retriever Tool for CrewAI\n",
    "from langchain.tools import Tool\n",
    "\n",
    "retriever_tool = Tool(\n",
    "    name=\"Document Retriever\",\n",
    "    func=lambda q: \"\\n\".join([doc.page_content for doc in retriever.get_relevant_documents(q)]),\n",
    "    description=\"Use this to retrieve relevant context from documents.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"HUGGINGFACEHUB_API_TOKEN\"\n",
    "\n",
    "model_id = \"google/flan-t5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c526544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Correct import\n",
    "import crewai\n",
    "print(crewai.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "retriever_tool = {\n",
    "    \"name\": \"Document Retriever\",\n",
    "    \"description\": \"Use this to retrieve relevant document chunks based on a query\",\n",
    "    \"func\": lambda q: \"\\n\".join([doc.page_content for doc in retriever.get_relevant_documents(q)])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b871b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = {\n",
    "    \"name\": \"Document Retriever\",\n",
    "    \"description\": \"Retrieves relevant chunks from the documents using a vectorstore retriever\",\n",
    "    \"func\": lambda q: \"\\n\".join([doc.page_content for doc in retriever.get_relevant_documents(q)])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent\n",
    "\n",
    "rag_agent = Agent(\n",
    "    role=\"RAG Specialist\",\n",
    "    goal=\"Answer questions using document chunks\",\n",
    "    backstory=\"You specialize in document-based question answering.\",\n",
    "    tools=[retriever_tool],  # âœ… List of dicts\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task, Crew\n",
    "\n",
    "task = Task(\n",
    "    description=\"Answer the question: What are the main themes in the text?\",\n",
    "    agent=rag_agent,\n",
    "    expected_output=\"A list of the main themes.\"\n",
    ")\n",
    "\n",
    "crew = Crew(agents=[rag_agent], tasks=[task])\n",
    "result = crew.run()\n",
    "\n",
    "print(\"\\nðŸ“Œ Final Answer:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai.tools import BaseTool\n",
    "from langchain import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "\n",
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "# 1. Load documents & create vectorstore\n",
    "docs = RecursiveCharacterTextSplitter(chunk_size=500).split_documents(\n",
    "    CSVLoader(file_path=r\"D:\\Users\\ramadeepthi.galla\\Documents\\sample.csv\").load()\n",
    ")\n",
    "vs = FAISS.from_documents(docs, HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n",
    "retriever = vs.as_retriever()\n",
    "\n",
    "# 2. Create a RetrieverTool\n",
    "class RetrieverInput(BaseModel):\n",
    "    q: str\n",
    "\n",
    "class RetrieverTool(BaseTool):\n",
    "    name: str = \"Document Retriever\"\n",
    "    description: str = \"Fetches relevant document chunks for a question\"\n",
    "    args_schema: type[BaseModel] = RetrieverInput\n",
    "\n",
    "    def _run(self, q: str) -> str:\n",
    "        return \"\\n\".join([d.page_content for d in retriever.get_relevant_documents(q)])\n",
    "\n",
    "# Local LLM \n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Now define the local wrapper (no BaseLLM import needed)\n",
    "class LocalHuggingFaceLLM:\n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "\n",
    "    def __call__(self, prompt: str, **kwargs) -> str:\n",
    "        return self.pipeline(prompt)[0]['generated_text']\n",
    "\n",
    "# âœ… Safe to instantiate now\n",
    "local_llm = LocalHuggingFaceLLM(pipe)\n",
    "\n",
    "\n",
    "\n",
    "rt = RetrieverTool()\n",
    "\n",
    "# 3. Set up LLM using LiteLLM and Hugging Face inference\n",
    "llm = LLM(\n",
    "    provider=\"huggingface\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    api_key=hf_token,\n",
    "    base_url=\"https://api-inference.huggingface.co\"\n",
    ")\n",
    "\n",
    "# 4. Build the Agent, Task, and Crew\n",
    "agent = Agent(\n",
    "    role=\"RAG Expert\",\n",
    "    goal=\"Answer questions using retrieved documents\",\n",
    "    backstory=\"An agent specialized in document-based QA.\",\n",
    "    tools=[rt],\n",
    "    llm=local_llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "task = Task(\n",
    "    description=\"Summarize the key points from the document.\",\n",
    "    expected_output=\"A concise list of key insights.\",\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    process=\"sequential\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 5. Execute\n",
    "print(\"âœ… Answer:\\n\", crew.kickoff())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c005ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crewai\n",
    "print(crewai.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
